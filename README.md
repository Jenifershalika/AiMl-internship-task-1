# AiMl-internship
# Titanic Dataset Preprocessing Project ğŸš¢

This project demonstrates how to clean and prepare a real-world dataset (Titanic dataset) for machine learning and analysis. It includes key data preprocessing steps using Python and pandas in Jupyter Notebook.

---

## ğŸ“‚ Dataset Overview

The dataset used in this project is the **Titanic - Machine Learning from Disaster** dataset from [Kaggle](https://www.kaggle.com/competitions/titanic/data).

It contains information about passengers on the Titanic and whether they survived. This dataset is commonly used for classification problems.

**Key columns include:**
- `PassengerId` â€” Unique ID
- `Pclass` â€” Ticket class (1st, 2nd, 3rd)
- `Name` â€” Passenger name
- `Sex` â€” Gender
- `Age` â€” Age in years
- `SibSp` â€” Number of siblings/spouses aboard
- `Parch` â€” Number of parents/children aboard
- `Ticket` â€” Ticket number
- `Fare` â€” Ticket price
- `Cabin` â€” Cabin number (many missing values)
- `Embarked` â€” Port of Embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)
- `Survived` â€” Survival (0 = No, 1 = Yes)

---

## ğŸ§¼ Data Preprocessing Steps

The following preprocessing steps are performed:

1. **Importing and Exploring the Dataset**
   - Checking null values
   - Understanding data types

2. **Handling Missing Values**
   - Filled missing `Age` and `Fare` using mean/median
   - Filled missing `Embarked` using mode
   - Dropped `Cabin` due to too many missing values

3. **Encoding Categorical Variables**
   - Converted `Sex` into binary (0: female, 1: male)
   - One-hot encoded `Embarked` (C, Q, S â†’ new columns)

4. **Normalization**
   - Scaled numerical columns (`Age`, `Fare`, `SibSp`, `Parch`) using `MinMaxScaler`

5. **Outlier Detection & Removal**
   - Used **boxplots** to visualize outliers
   - Removed outliers using **IQR method**

---

## ğŸ”§ Tools Used

- Python 3.x
- Jupyter Notebook
- pandas
- matplotlib
- scikit-learn

---

## ğŸ“Š Sample Output

Cleaned dataset with numerical and encoded columns, ready for machine learning models like:
- Logistic Regression
- Decision Trees
- KNN
- SVM

---

## ğŸ“ Files in this Repository

- `Titanic_Project.ipynb` â€” Jupyter notebook with full preprocessing code
- `titanic.csv` â€” Raw dataset (if included)
- `README.md` â€” Project overview and documentation

---

## ğŸ§  Future Improvements

- Handle `Cabin` column with feature engineering
- Apply advanced imputation (e.g., KNNImputer)
- Train and evaluate machine learning models

---
# ğŸ§  Logistic Regression - Breast Cancer Classification

This project demonstrates how to use **Logistic Regression** to classify breast cancer tumors as **malignant (M)** or **benign (B)** using the [Breast Cancer Wisconsin (Diagnostic) Data Set](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). The model is built with **scikit-learn** and evaluated using accuracy, confusion matrix, classification report, and ROC curve.

---

## ğŸ“Œ Project Tasks

- âœ… Load and clean the dataset
- âœ… Encode categorical labels (M/B) into numerical values (1/0)
- âœ… Standardize features using `StandardScaler`
- âœ… Split dataset into train and test sets
- âœ… Train a Logistic Regression model
- âœ… Evaluate the model using metrics and ROC curve
- âœ… Perform threshold tuning

---

## ğŸ“Š Dataset Information

- **Target Column**: `diagnosis`
- **Target Classes**:
  - `M`: Malignant (1)
  - `B`: Benign (0)
- **Features**: 30 numeric features like radius, texture, area, smoothness, etc.
- **Dropped Columns**: `id`, `Unnamed: 32` (not relevant for prediction)

---

## ğŸ›  Technologies Used

- Python
- Pandas
- NumPy
- Matplotlib
- scikit-learn

---

## ğŸš€ How to Run

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/your-repo-name.git
   cd your-repo-name


## ğŸ™Œ Credits

Dataset from [Kaggle Titanic Competition](https://www.kaggle.com/competitions/titanic)

---

